{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\nimport os\n\n\ndata = []\nlabels = []\nIMG_SIZE = 130\nfor i in os.listdir('/kaggle/input/nn23-sports-image-classification/Train'):\n    img = cv.imread('/kaggle/input/nn23-sports-image-classification/Train/'+i)\n    img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n    img = cv.resize(img,(IMG_SIZE,IMG_SIZE))\n    data.append(img)\n    labels.append(i.split('_')[0])\n\nprint(len(data))\nprint(labels[0])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-13T02:42:42.843532Z","iopub.execute_input":"2022-12-13T02:42:42.843931Z","iopub.status.idle":"2022-12-13T02:42:51.743933Z","shell.execute_reply.started":"2022-12-13T02:42:42.843895Z","shell.execute_reply":"2022-12-13T02:42:51.742707Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"1681\nYoga\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nle = LabelEncoder()\ntrain_labels = le.fit_transform(labels)\ntrain_labels = np_utils.to_categorical(train_labels, len(np.unique(train_labels)))\n\n# split the data into training and testing\n(trainX, testX, trainY, testY) = train_test_split(np.array(data), np.array(train_labels), test_size=0.20, random_state=42)\n\n# normalize the data\ntrainX = trainX.astype(\"float\") / 255.0\ntestX = testX.astype(\"float\") / 255.0\n\nprint(len(trainX))\nprint(len(testX))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:27:50.064876Z","iopub.execute_input":"2022-12-13T03:27:50.065326Z","iopub.status.idle":"2022-12-13T03:27:50.406215Z","shell.execute_reply.started":"2022-12-13T03:27:50.065287Z","shell.execute_reply":"2022-12-13T03:27:50.404809Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"1344\n337\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\nval_datagen = ImageDataGenerator()\ntrain_gen = train_datagen.flow(trainX,trainY,batch_size=32)\nval_gen = val_datagen.flow(testX,testY,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:27:53.177677Z","iopub.execute_input":"2022-12-13T03:27:53.178104Z","iopub.status.idle":"2022-12-13T03:27:53.356027Z","shell.execute_reply.started":"2022-12-13T03:27:53.178066Z","shell.execute_reply":"2022-12-13T03:27:53.354870Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n\nmodel = Sequential()\n# l2 = tf.keras.regularizers.l2(0.0001)\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(IMG_SIZE,IMG_SIZE,3)))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:29:01.102538Z","iopub.execute_input":"2022-12-13T03:29:01.102995Z","iopub.status.idle":"2022-12-13T03:29:01.217224Z","shell.execute_reply.started":"2022-12-13T03:29:01.102947Z","shell.execute_reply":"2022-12-13T03:29:01.216172Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:29:03.928337Z","iopub.execute_input":"2022-12-13T03:29:03.928816Z","iopub.status.idle":"2022-12-13T03:29:03.939732Z","shell.execute_reply.started":"2022-12-13T03:29:03.928772Z","shell.execute_reply":"2022-12-13T03:29:03.937600Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Model: \"sequential_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_104 (Conv2D)          (None, 128, 128, 32)      896       \n_________________________________________________________________\nmax_pooling2d_98 (MaxPooling (None, 64, 64, 32)        0         \n_________________________________________________________________\nconv2d_105 (Conv2D)          (None, 62, 62, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_99 (MaxPooling (None, 31, 31, 64)        0         \n_________________________________________________________________\nconv2d_106 (Conv2D)          (None, 29, 29, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_100 (MaxPoolin (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_107 (Conv2D)          (None, 12, 12, 64)        73792     \n_________________________________________________________________\nmax_pooling2d_101 (MaxPoolin (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_108 (Conv2D)          (None, 4, 4, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_102 (MaxPoolin (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten_14 (Flatten)         (None, 256)               0         \n_________________________________________________________________\ndense_40 (Dense)             (None, 512)               131584    \n_________________________________________________________________\ndropout_26 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_41 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndropout_27 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_42 (Dense)             (None, 6)                 774       \n=================================================================\nTotal params: 401,990\nTrainable params: 401,990\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n\ncheckpoint = ModelCheckpoint('model.h5',monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=False,mode='auto',period=1)\nearly = EarlyStopping(monitor='val_loss',min_delta=0,patience=20,verbose=1,mode='auto')\n\n\nhist = model.fit(train_gen,epochs=400,validation_data=val_gen,callbacks=[checkpoint,early])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:29:12.775819Z","iopub.execute_input":"2022-12-13T03:29:12.776257Z","iopub.status.idle":"2022-12-13T04:10:58.775052Z","shell.execute_reply.started":"2022-12-13T03:29:12.776219Z","shell.execute_reply":"2022-12-13T04:10:58.773682Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Epoch 1/400\n135/135 [==============================] - 22s 156ms/step - loss: 1.7455 - accuracy: 0.3118 - val_loss: 1.6066 - val_accuracy: 0.3947\n\nEpoch 00001: val_loss improved from inf to 1.60658, saving model to model.h5\nEpoch 2/400\n135/135 [==============================] - 20s 148ms/step - loss: 1.5096 - accuracy: 0.4539 - val_loss: 1.4705 - val_accuracy: 0.4540\n\nEpoch 00002: val_loss improved from 1.60658 to 1.47050, saving model to model.h5\nEpoch 3/400\n135/135 [==============================] - 20s 152ms/step - loss: 1.3945 - accuracy: 0.4903 - val_loss: 1.3060 - val_accuracy: 0.5015\n\nEpoch 00003: val_loss improved from 1.47050 to 1.30600, saving model to model.h5\nEpoch 4/400\n135/135 [==============================] - 21s 153ms/step - loss: 1.3106 - accuracy: 0.5149 - val_loss: 1.3300 - val_accuracy: 0.5104\n\nEpoch 00004: val_loss did not improve from 1.30600\nEpoch 5/400\n135/135 [==============================] - 21s 152ms/step - loss: 1.2388 - accuracy: 0.5499 - val_loss: 1.2081 - val_accuracy: 0.6053\n\nEpoch 00005: val_loss improved from 1.30600 to 1.20815, saving model to model.h5\nEpoch 6/400\n135/135 [==============================] - 20s 146ms/step - loss: 1.2158 - accuracy: 0.5677 - val_loss: 1.2706 - val_accuracy: 0.5223\n\nEpoch 00006: val_loss did not improve from 1.20815\nEpoch 7/400\n135/135 [==============================] - 20s 151ms/step - loss: 1.1201 - accuracy: 0.6034 - val_loss: 1.2043 - val_accuracy: 0.5875\n\nEpoch 00007: val_loss improved from 1.20815 to 1.20430, saving model to model.h5\nEpoch 8/400\n135/135 [==============================] - 21s 153ms/step - loss: 1.0866 - accuracy: 0.6161 - val_loss: 1.0242 - val_accuracy: 0.6617\n\nEpoch 00008: val_loss improved from 1.20430 to 1.02424, saving model to model.h5\nEpoch 9/400\n135/135 [==============================] - 20s 148ms/step - loss: 1.0138 - accuracy: 0.6562 - val_loss: 0.9799 - val_accuracy: 0.6706\n\nEpoch 00009: val_loss improved from 1.02424 to 0.97994, saving model to model.h5\nEpoch 10/400\n135/135 [==============================] - 21s 152ms/step - loss: 1.0018 - accuracy: 0.6607 - val_loss: 1.0303 - val_accuracy: 0.6469\n\nEpoch 00010: val_loss did not improve from 0.97994\nEpoch 11/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.9744 - accuracy: 0.6711 - val_loss: 0.9533 - val_accuracy: 0.6766\n\nEpoch 00011: val_loss improved from 0.97994 to 0.95326, saving model to model.h5\nEpoch 12/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.9245 - accuracy: 0.6778 - val_loss: 0.9240 - val_accuracy: 0.6944\n\nEpoch 00012: val_loss improved from 0.95326 to 0.92400, saving model to model.h5\nEpoch 13/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.9210 - accuracy: 0.6927 - val_loss: 0.9271 - val_accuracy: 0.6944\n\nEpoch 00013: val_loss did not improve from 0.92400\nEpoch 14/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.8955 - accuracy: 0.7121 - val_loss: 1.0399 - val_accuracy: 0.6469\n\nEpoch 00014: val_loss did not improve from 0.92400\nEpoch 15/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.8886 - accuracy: 0.7054 - val_loss: 1.1013 - val_accuracy: 0.6291\n\nEpoch 00015: val_loss did not improve from 0.92400\nEpoch 16/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.8734 - accuracy: 0.7076 - val_loss: 0.8513 - val_accuracy: 0.7270\n\nEpoch 00016: val_loss improved from 0.92400 to 0.85134, saving model to model.h5\nEpoch 17/400\n135/135 [==============================] - 20s 149ms/step - loss: 0.8436 - accuracy: 0.7314 - val_loss: 0.9195 - val_accuracy: 0.6795\n\nEpoch 00017: val_loss did not improve from 0.85134\nEpoch 18/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.8291 - accuracy: 0.7344 - val_loss: 0.9211 - val_accuracy: 0.6944\n\nEpoch 00018: val_loss did not improve from 0.85134\nEpoch 19/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.8218 - accuracy: 0.7374 - val_loss: 0.8685 - val_accuracy: 0.6973\n\nEpoch 00019: val_loss did not improve from 0.85134\nEpoch 20/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.8107 - accuracy: 0.7381 - val_loss: 0.8271 - val_accuracy: 0.7211\n\nEpoch 00020: val_loss improved from 0.85134 to 0.82707, saving model to model.h5\nEpoch 21/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.8013 - accuracy: 0.7336 - val_loss: 1.0212 - val_accuracy: 0.6766\n\nEpoch 00021: val_loss did not improve from 0.82707\nEpoch 22/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.8023 - accuracy: 0.7374 - val_loss: 0.7825 - val_accuracy: 0.7507\n\nEpoch 00022: val_loss improved from 0.82707 to 0.78251, saving model to model.h5\nEpoch 23/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.7887 - accuracy: 0.7545 - val_loss: 0.9590 - val_accuracy: 0.6825\n\nEpoch 00023: val_loss did not improve from 0.78251\nEpoch 24/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.7650 - accuracy: 0.7507 - val_loss: 0.7904 - val_accuracy: 0.7478\n\nEpoch 00024: val_loss did not improve from 0.78251\nEpoch 25/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.7424 - accuracy: 0.7493 - val_loss: 0.8744 - val_accuracy: 0.7092\n\nEpoch 00025: val_loss did not improve from 0.78251\nEpoch 26/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.7869 - accuracy: 0.7396 - val_loss: 0.8669 - val_accuracy: 0.7151\n\nEpoch 00026: val_loss did not improve from 0.78251\nEpoch 27/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.7600 - accuracy: 0.7537 - val_loss: 0.7864 - val_accuracy: 0.7329\n\nEpoch 00027: val_loss did not improve from 0.78251\nEpoch 28/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.7645 - accuracy: 0.7455 - val_loss: 0.7934 - val_accuracy: 0.7359\n\nEpoch 00028: val_loss did not improve from 0.78251\nEpoch 29/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.7315 - accuracy: 0.7671 - val_loss: 0.8624 - val_accuracy: 0.7062\n\nEpoch 00029: val_loss did not improve from 0.78251\nEpoch 30/400\n135/135 [==============================] - 20s 152ms/step - loss: 0.7427 - accuracy: 0.7612 - val_loss: 0.8742 - val_accuracy: 0.7329\n\nEpoch 00030: val_loss did not improve from 0.78251\nEpoch 31/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.7223 - accuracy: 0.7783 - val_loss: 0.8511 - val_accuracy: 0.7300\n\nEpoch 00031: val_loss did not improve from 0.78251\nEpoch 32/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.6983 - accuracy: 0.7820 - val_loss: 0.8157 - val_accuracy: 0.7389\n\nEpoch 00032: val_loss did not improve from 0.78251\nEpoch 33/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.7056 - accuracy: 0.7723 - val_loss: 0.7476 - val_accuracy: 0.7537\n\nEpoch 00033: val_loss improved from 0.78251 to 0.74756, saving model to model.h5\nEpoch 34/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.6921 - accuracy: 0.7820 - val_loss: 0.8404 - val_accuracy: 0.7300\n\nEpoch 00034: val_loss did not improve from 0.74756\nEpoch 35/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.6851 - accuracy: 0.7746 - val_loss: 0.8387 - val_accuracy: 0.7567\n\nEpoch 00035: val_loss did not improve from 0.74756\nEpoch 36/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.6932 - accuracy: 0.7909 - val_loss: 0.8628 - val_accuracy: 0.7240\n\nEpoch 00036: val_loss did not improve from 0.74756\nEpoch 37/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.6955 - accuracy: 0.7798 - val_loss: 0.8527 - val_accuracy: 0.7270\n\nEpoch 00037: val_loss did not improve from 0.74756\nEpoch 38/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.6489 - accuracy: 0.7872 - val_loss: 0.8813 - val_accuracy: 0.7329\n\nEpoch 00038: val_loss did not improve from 0.74756\nEpoch 39/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.6749 - accuracy: 0.7872 - val_loss: 0.7827 - val_accuracy: 0.7507\n\nEpoch 00039: val_loss did not improve from 0.74756\nEpoch 40/400\n135/135 [==============================] - 20s 149ms/step - loss: 0.6602 - accuracy: 0.7865 - val_loss: 0.8015 - val_accuracy: 0.7478\n\nEpoch 00040: val_loss did not improve from 0.74756\nEpoch 41/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.6396 - accuracy: 0.7976 - val_loss: 1.0230 - val_accuracy: 0.6973\n\nEpoch 00041: val_loss did not improve from 0.74756\nEpoch 42/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.6477 - accuracy: 0.7961 - val_loss: 0.8649 - val_accuracy: 0.7448\n\nEpoch 00042: val_loss did not improve from 0.74756\nEpoch 43/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.6496 - accuracy: 0.7932 - val_loss: 0.9463 - val_accuracy: 0.7003\n\nEpoch 00043: val_loss did not improve from 0.74756\nEpoch 44/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.6246 - accuracy: 0.8080 - val_loss: 0.7148 - val_accuracy: 0.7715\n\nEpoch 00044: val_loss improved from 0.74756 to 0.71485, saving model to model.h5\nEpoch 45/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.6109 - accuracy: 0.8103 - val_loss: 0.7589 - val_accuracy: 0.7685\n\nEpoch 00045: val_loss did not improve from 0.71485\nEpoch 46/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.6074 - accuracy: 0.8147 - val_loss: 0.7937 - val_accuracy: 0.7567\n\nEpoch 00046: val_loss did not improve from 0.71485\nEpoch 47/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.5971 - accuracy: 0.8110 - val_loss: 0.7427 - val_accuracy: 0.7656\n\nEpoch 00047: val_loss did not improve from 0.71485\nEpoch 48/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.5763 - accuracy: 0.8207 - val_loss: 0.7703 - val_accuracy: 0.7745\n\nEpoch 00048: val_loss did not improve from 0.71485\nEpoch 49/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5769 - accuracy: 0.8229 - val_loss: 0.7688 - val_accuracy: 0.7685\n\nEpoch 00049: val_loss did not improve from 0.71485\nEpoch 50/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.5563 - accuracy: 0.8356 - val_loss: 0.7443 - val_accuracy: 0.7715\n\nEpoch 00050: val_loss did not improve from 0.71485\nEpoch 51/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.5601 - accuracy: 0.8304 - val_loss: 0.7586 - val_accuracy: 0.7804\n\nEpoch 00051: val_loss did not improve from 0.71485\nEpoch 52/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.5866 - accuracy: 0.8207 - val_loss: 0.7698 - val_accuracy: 0.7834\n\nEpoch 00052: val_loss did not improve from 0.71485\nEpoch 53/400\n135/135 [==============================] - 21s 151ms/step - loss: 0.5630 - accuracy: 0.8363 - val_loss: 0.8375 - val_accuracy: 0.7389\n\nEpoch 00053: val_loss did not improve from 0.71485\nEpoch 54/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.5528 - accuracy: 0.8281 - val_loss: 0.9538 - val_accuracy: 0.7092\n\nEpoch 00054: val_loss did not improve from 0.71485\nEpoch 55/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.5268 - accuracy: 0.8490 - val_loss: 0.7265 - val_accuracy: 0.7804\n\nEpoch 00055: val_loss did not improve from 0.71485\nEpoch 56/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.5785 - accuracy: 0.8222 - val_loss: 0.7113 - val_accuracy: 0.7864\n\nEpoch 00056: val_loss improved from 0.71485 to 0.71129, saving model to model.h5\nEpoch 57/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.5367 - accuracy: 0.8363 - val_loss: 0.7685 - val_accuracy: 0.7596\n\nEpoch 00057: val_loss did not improve from 0.71129\nEpoch 58/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5371 - accuracy: 0.8333 - val_loss: 0.7139 - val_accuracy: 0.7774\n\nEpoch 00058: val_loss did not improve from 0.71129\nEpoch 59/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5357 - accuracy: 0.8445 - val_loss: 0.7925 - val_accuracy: 0.7626\n\nEpoch 00059: val_loss did not improve from 0.71129\nEpoch 60/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.5128 - accuracy: 0.8356 - val_loss: 0.6940 - val_accuracy: 0.8042\n\nEpoch 00060: val_loss improved from 0.71129 to 0.69402, saving model to model.h5\nEpoch 61/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5292 - accuracy: 0.8371 - val_loss: 0.8607 - val_accuracy: 0.7389\n\nEpoch 00061: val_loss did not improve from 0.69402\nEpoch 62/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.5438 - accuracy: 0.8348 - val_loss: 0.7476 - val_accuracy: 0.7893\n\nEpoch 00062: val_loss did not improve from 0.69402\nEpoch 63/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5332 - accuracy: 0.8333 - val_loss: 0.6908 - val_accuracy: 0.7982\n\nEpoch 00063: val_loss improved from 0.69402 to 0.69085, saving model to model.h5\nEpoch 64/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4993 - accuracy: 0.8534 - val_loss: 0.6579 - val_accuracy: 0.8071\n\nEpoch 00064: val_loss improved from 0.69085 to 0.65793, saving model to model.h5\nEpoch 65/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.5193 - accuracy: 0.8475 - val_loss: 0.7495 - val_accuracy: 0.7685\n\nEpoch 00065: val_loss did not improve from 0.65793\nEpoch 66/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.5158 - accuracy: 0.8490 - val_loss: 0.7512 - val_accuracy: 0.7834\n\nEpoch 00066: val_loss did not improve from 0.65793\nEpoch 67/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4919 - accuracy: 0.8504 - val_loss: 0.7614 - val_accuracy: 0.7893\n\nEpoch 00067: val_loss did not improve from 0.65793\nEpoch 68/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.4957 - accuracy: 0.8475 - val_loss: 0.6693 - val_accuracy: 0.7834\n\nEpoch 00068: val_loss did not improve from 0.65793\nEpoch 69/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.4879 - accuracy: 0.8497 - val_loss: 0.7544 - val_accuracy: 0.7596\n\nEpoch 00069: val_loss did not improve from 0.65793\nEpoch 70/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.4789 - accuracy: 0.8616 - val_loss: 0.7662 - val_accuracy: 0.7834\n\nEpoch 00070: val_loss did not improve from 0.65793\nEpoch 71/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.4766 - accuracy: 0.8564 - val_loss: 0.7437 - val_accuracy: 0.7834\n\nEpoch 00071: val_loss did not improve from 0.65793\nEpoch 72/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4788 - accuracy: 0.8482 - val_loss: 0.7473 - val_accuracy: 0.7804\n\nEpoch 00072: val_loss did not improve from 0.65793\nEpoch 73/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.4632 - accuracy: 0.8616 - val_loss: 0.7111 - val_accuracy: 0.8101\n\nEpoch 00073: val_loss did not improve from 0.65793\nEpoch 74/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.4568 - accuracy: 0.8653 - val_loss: 0.8043 - val_accuracy: 0.7685\n\nEpoch 00074: val_loss did not improve from 0.65793\nEpoch 75/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4878 - accuracy: 0.8609 - val_loss: 0.7021 - val_accuracy: 0.7982\n\nEpoch 00075: val_loss did not improve from 0.65793\nEpoch 76/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.4577 - accuracy: 0.8534 - val_loss: 0.7449 - val_accuracy: 0.7923\n\nEpoch 00076: val_loss did not improve from 0.65793\nEpoch 77/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4578 - accuracy: 0.8586 - val_loss: 0.7036 - val_accuracy: 0.7804\n\nEpoch 00077: val_loss did not improve from 0.65793\nEpoch 78/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.4251 - accuracy: 0.8765 - val_loss: 0.6656 - val_accuracy: 0.8012\n\nEpoch 00078: val_loss did not improve from 0.65793\nEpoch 79/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.4452 - accuracy: 0.8579 - val_loss: 0.8853 - val_accuracy: 0.7418\n\nEpoch 00079: val_loss did not improve from 0.65793\nEpoch 80/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.4566 - accuracy: 0.8690 - val_loss: 0.7109 - val_accuracy: 0.7982\n\nEpoch 00080: val_loss did not improve from 0.65793\nEpoch 81/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.4375 - accuracy: 0.8676 - val_loss: 0.9428 - val_accuracy: 0.7329\n\nEpoch 00081: val_loss did not improve from 0.65793\nEpoch 82/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4698 - accuracy: 0.8557 - val_loss: 0.6702 - val_accuracy: 0.8190\n\nEpoch 00082: val_loss did not improve from 0.65793\nEpoch 83/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.4095 - accuracy: 0.8765 - val_loss: 0.6510 - val_accuracy: 0.8220\n\nEpoch 00083: val_loss improved from 0.65793 to 0.65104, saving model to model.h5\nEpoch 84/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.4550 - accuracy: 0.8609 - val_loss: 0.6893 - val_accuracy: 0.7982\n\nEpoch 00084: val_loss did not improve from 0.65104\nEpoch 85/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.4301 - accuracy: 0.8638 - val_loss: 0.7188 - val_accuracy: 0.7982\n\nEpoch 00085: val_loss did not improve from 0.65104\nEpoch 86/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4367 - accuracy: 0.8720 - val_loss: 0.6640 - val_accuracy: 0.8160\n\nEpoch 00086: val_loss did not improve from 0.65104\nEpoch 87/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.4448 - accuracy: 0.8713 - val_loss: 0.6703 - val_accuracy: 0.8131\n\nEpoch 00087: val_loss did not improve from 0.65104\nEpoch 88/400\n135/135 [==============================] - 20s 150ms/step - loss: 0.4093 - accuracy: 0.8832 - val_loss: 0.8032 - val_accuracy: 0.7893\n\nEpoch 00088: val_loss did not improve from 0.65104\nEpoch 89/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4290 - accuracy: 0.8720 - val_loss: 0.6713 - val_accuracy: 0.8131\n\nEpoch 00089: val_loss did not improve from 0.65104\nEpoch 90/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.4293 - accuracy: 0.8787 - val_loss: 0.6601 - val_accuracy: 0.8249\n\nEpoch 00090: val_loss did not improve from 0.65104\nEpoch 91/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.4302 - accuracy: 0.8839 - val_loss: 0.7313 - val_accuracy: 0.8101\n\nEpoch 00091: val_loss did not improve from 0.65104\nEpoch 92/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.4142 - accuracy: 0.8646 - val_loss: 0.6973 - val_accuracy: 0.8190\n\nEpoch 00092: val_loss did not improve from 0.65104\nEpoch 93/400\n135/135 [==============================] - 20s 150ms/step - loss: 0.4059 - accuracy: 0.8899 - val_loss: 0.6737 - val_accuracy: 0.8190\n\nEpoch 00093: val_loss did not improve from 0.65104\nEpoch 94/400\n135/135 [==============================] - 20s 150ms/step - loss: 0.4120 - accuracy: 0.8765 - val_loss: 0.8601 - val_accuracy: 0.7685\n\nEpoch 00094: val_loss did not improve from 0.65104\nEpoch 95/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.4329 - accuracy: 0.8705 - val_loss: 0.7269 - val_accuracy: 0.8071\n\nEpoch 00095: val_loss did not improve from 0.65104\nEpoch 96/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.4111 - accuracy: 0.8817 - val_loss: 0.7777 - val_accuracy: 0.8071\n\nEpoch 00096: val_loss did not improve from 0.65104\nEpoch 97/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.3873 - accuracy: 0.8847 - val_loss: 0.7125 - val_accuracy: 0.8042\n\nEpoch 00097: val_loss did not improve from 0.65104\nEpoch 98/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.3923 - accuracy: 0.8862 - val_loss: 0.7313 - val_accuracy: 0.8012\n\nEpoch 00098: val_loss did not improve from 0.65104\nEpoch 99/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.3614 - accuracy: 0.8958 - val_loss: 0.7484 - val_accuracy: 0.8160\n\nEpoch 00099: val_loss did not improve from 0.65104\nEpoch 100/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.3992 - accuracy: 0.8824 - val_loss: 0.7445 - val_accuracy: 0.8071\n\nEpoch 00100: val_loss did not improve from 0.65104\nEpoch 101/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.4139 - accuracy: 0.8795 - val_loss: 0.6276 - val_accuracy: 0.8309\n\nEpoch 00101: val_loss improved from 0.65104 to 0.62763, saving model to model.h5\nEpoch 102/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.4047 - accuracy: 0.8869 - val_loss: 0.6781 - val_accuracy: 0.8042\n\nEpoch 00102: val_loss did not improve from 0.62763\nEpoch 103/400\n135/135 [==============================] - 21s 154ms/step - loss: 0.3603 - accuracy: 0.9018 - val_loss: 0.6902 - val_accuracy: 0.8101\n\nEpoch 00103: val_loss did not improve from 0.62763\nEpoch 104/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.3542 - accuracy: 0.8988 - val_loss: 0.6529 - val_accuracy: 0.8131\n\nEpoch 00104: val_loss did not improve from 0.62763\nEpoch 105/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.3853 - accuracy: 0.8906 - val_loss: 0.6314 - val_accuracy: 0.8131\n\nEpoch 00105: val_loss did not improve from 0.62763\nEpoch 106/400\n135/135 [==============================] - 20s 146ms/step - loss: 0.3620 - accuracy: 0.8966 - val_loss: 0.8205 - val_accuracy: 0.7774\n\nEpoch 00106: val_loss did not improve from 0.62763\nEpoch 107/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.4017 - accuracy: 0.8891 - val_loss: 0.7115 - val_accuracy: 0.8042\n\nEpoch 00107: val_loss did not improve from 0.62763\nEpoch 108/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.3837 - accuracy: 0.8869 - val_loss: 0.7115 - val_accuracy: 0.8071\n\nEpoch 00108: val_loss did not improve from 0.62763\nEpoch 109/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.3687 - accuracy: 0.8869 - val_loss: 0.7614 - val_accuracy: 0.7923\n\nEpoch 00109: val_loss did not improve from 0.62763\nEpoch 110/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.3581 - accuracy: 0.8906 - val_loss: 0.6662 - val_accuracy: 0.8279\n\nEpoch 00110: val_loss did not improve from 0.62763\nEpoch 111/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.3788 - accuracy: 0.8847 - val_loss: 0.7183 - val_accuracy: 0.8190\n\nEpoch 00111: val_loss did not improve from 0.62763\nEpoch 112/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.3771 - accuracy: 0.8914 - val_loss: 0.7655 - val_accuracy: 0.7834\n\nEpoch 00112: val_loss did not improve from 0.62763\nEpoch 113/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.3764 - accuracy: 0.8981 - val_loss: 0.6949 - val_accuracy: 0.8012\n\nEpoch 00113: val_loss did not improve from 0.62763\nEpoch 114/400\n135/135 [==============================] - 20s 150ms/step - loss: 0.3613 - accuracy: 0.8973 - val_loss: 0.6734 - val_accuracy: 0.8338\n\nEpoch 00114: val_loss did not improve from 0.62763\nEpoch 115/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.3635 - accuracy: 0.8891 - val_loss: 0.7493 - val_accuracy: 0.7953\n\nEpoch 00115: val_loss did not improve from 0.62763\nEpoch 116/400\n135/135 [==============================] - 20s 151ms/step - loss: 0.3311 - accuracy: 0.9100 - val_loss: 0.8846 - val_accuracy: 0.7626\n\nEpoch 00116: val_loss did not improve from 0.62763\nEpoch 117/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.3780 - accuracy: 0.8951 - val_loss: 0.7228 - val_accuracy: 0.8071\n\nEpoch 00117: val_loss did not improve from 0.62763\nEpoch 118/400\n135/135 [==============================] - 20s 147ms/step - loss: 0.3506 - accuracy: 0.8996 - val_loss: 0.7203 - val_accuracy: 0.8071\n\nEpoch 00118: val_loss did not improve from 0.62763\nEpoch 119/400\n135/135 [==============================] - 21s 152ms/step - loss: 0.3209 - accuracy: 0.9122 - val_loss: 0.7372 - val_accuracy: 0.8042\n\nEpoch 00119: val_loss did not improve from 0.62763\nEpoch 120/400\n135/135 [==============================] - 20s 148ms/step - loss: 0.3593 - accuracy: 0.8966 - val_loss: 0.8376 - val_accuracy: 0.7864\n\nEpoch 00120: val_loss did not improve from 0.62763\nEpoch 121/400\n135/135 [==============================] - 21s 153ms/step - loss: 0.3370 - accuracy: 0.8988 - val_loss: 0.7716 - val_accuracy: 0.7923\n\nEpoch 00121: val_loss did not improve from 0.62763\nEpoch 00121: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(hist.history['loss'], label='train loss')\nplt.plot(hist.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:20:46.147505Z","iopub.execute_input":"2022-12-13T03:20:46.147844Z","iopub.status.idle":"2022-12-13T03:20:46.350594Z","shell.execute_reply.started":"2022-12-13T03:20:46.147812Z","shell.execute_reply":"2022-12-13T03:20:46.349207Z"},"trusted":true},"execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(testX,testY)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:20:46.351799Z","iopub.execute_input":"2022-12-13T03:20:46.352754Z","iopub.status.idle":"2022-12-13T03:20:47.602951Z","shell.execute_reply.started":"2022-12-13T03:20:46.352715Z","shell.execute_reply":"2022-12-13T03:20:47.601992Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"11/11 [==============================] - 1s 80ms/step - loss: 0.6279 - accuracy: 0.8190\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"[0.6278781890869141, 0.8189911246299744]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Reading Test Data","metadata":{}},{"cell_type":"code","source":"test_data = []\nfor i in os.listdir('/kaggle/input/nn23-sports-image-classification/Test'):\n    img = cv.imread('/kaggle/input/nn23-sports-image-classification/Test/'+i)\n    img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n    img = cv.resize(img,(IMG_SIZE,IMG_SIZE))\n    test_data.append(np.array(img))\ntest_data = np.array(test_data)\ntest_data = test_data/255.0\n\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:20:47.603942Z","iopub.execute_input":"2022-12-13T03:20:47.604280Z","iopub.status.idle":"2022-12-13T03:20:54.627435Z","shell.execute_reply.started":"2022-12-13T03:20:47.604250Z","shell.execute_reply":"2022-12-13T03:20:54.625816Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"688\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_data)\npred = np.argmax(pred,axis=1)\n# pred = le.inverse_transform(pred)\ndf = pd.DataFrame({'image_name':os.listdir('/kaggle/input/nn23-sports-image-classification/Test'),'Label':pred})\ndf.to_csv('submission.csv',index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:22:18.711815Z","iopub.execute_input":"2022-12-13T03:22:18.712590Z","iopub.status.idle":"2022-12-13T03:22:20.613634Z","shell.execute_reply.started":"2022-12-13T03:22:18.712547Z","shell.execute_reply":"2022-12-13T03:22:20.612256Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"    image_name  Label\n0      623.jpg      1\n1      208.jpg      5\n2      473.jpg      0\n3      333.jpg      1\n4      537.jpg      1\n..         ...    ...\n683    364.jpg      2\n684     90.jpg      3\n685    599.jpg      2\n686     25.jpg      4\n687    147.jpg      3\n\n[688 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>623.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>208.jpg</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>473.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>537.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>364.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>90.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>599.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>25.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>147.jpg</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>688 rows  2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('model.h5')\nimport pickle\nf = open('label_encoder.pkl', \"wb\")\nf.write(pickle.dumps(le))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:20:56.600705Z","iopub.execute_input":"2022-12-13T03:20:56.601056Z","iopub.status.idle":"2022-12-13T03:20:56.652771Z","shell.execute_reply.started":"2022-12-13T03:20:56.601022Z","shell.execute_reply":"2022-12-13T03:20:56.651675Z"},"trusted":true},"execution_count":79,"outputs":[]}]}